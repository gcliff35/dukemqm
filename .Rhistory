predictions_glm <- predict(object = log.reg2, newdata = test[-17], type = "response")
head(predictions_glm, n = 30)
binary_glm <- as.factor(ifelse(predictions_glm > 0.5, 1, 0))
head(binary_glm, n = 30)
###CONFUSIONMATRIX####
binary_glm <- as.factor(binary_glm)
test$Default <- as.factor(test$Default)
set.seed(1234)
confusionMatrix(data = binary_glm, reference = test$Default)
####AUC######
pred_ROCR <- prediction(predictions_glm, test$Default)
auc_ROCR <- performance(pred_ROCR, measure = 'auc')
plot(performance(pred_ROCR, measure = 'tpr', x.measure = 'fpr'), colorize = TRUE,
print.cutoffs.at = seq(0, 1, 0.1), text.adj = c(-0.2, 1.7))
####AREAUNDERCURVE####
paste(signif(auc_ROCR@y.values[[1]]))
#######DECISIONTREE##########
decision <- rpart(Default ~., data = train, method = 'class')
set.seed(1234)
confusionMatrix(data = binary_glm, reference = test$Default)
library(caret)
###CONFUSIONMATRIX####
binary_glm <- as.factor(binary_glm)
test$Default <- as.factor(test$Default)
set.seed(1234)
confusionMatrix(data = binary_glm, reference = test$Default)
####AUC######
pred_ROCR <- prediction(predictions_glm, test$Default)
auc_ROCR <- performance(pred_ROCR, measure = 'auc')
plot(performance(pred_ROCR, measure = 'tpr', x.measure = 'fpr'), colorize = TRUE,
print.cutoffs.at = seq(0, 1, 0.1), text.adj = c(-0.2, 1.7))
####AREAUNDERCURVE####
paste(signif(auc_ROCR@y.values[[1]]))
#######DECISIONTREE##########
decision <- rpart(Default ~., data = train, method = 'class')
install.packages("tree")
library(tree)
library(tree)
decision <- tree(Default ~ Age + Income + LoanAmount + CreditScore + MonthsEmployed + NumCreditLines + InterestRate + DTIRatio + Education + EmploymentType + MaritalStatus + HasMortgage + HasDependents + LoanPurpose + HasCoSigner, data = train)
plot(decision)
text(decision)
decision <- tree(Default ~ Age + Income + LoanAmount + CreditScore, data = train)
plot(decision)
text(decision)
decision <- tree(Default ~ Age + Income + LoanAmount + CreditScore + MonthsEmployed + NumCreditLines + InterestRate + DTIRatio + Education + EmploymentType + MaritalStatus + HasMortgage + HasDependents + LoanPurpose + HasCoSigner, data = train)
plot(decision)
text(decision)
partition.tree(decision)
####FOREST###
forest <- randomForest(Default ~ ., data = train, nodesize=5, ntree = 500, mtry = 4)
library(randomForest)
####FOREST###
forest <- randomForest(Default ~ ., data = train, nodesize=5, ntree = 500, mtry = 4)
predictions_forest <- predict(object = forest, newdata = test[-17], type = "response")
head(predictions_forest, n = 30)
binary_forest <- as.factor(ifelse(predictions_glm > 0.5, 1, 0))
head(binary_forest, n = 30)
binary_forest <- as.factor(binary_forest)
test$Default <- as.factor(test$Default)
set.seed(1234)
confusionMatrix2(data = binary_forest, reference = test$Default)
confusionMatrix(data = binary_forest, reference = test$Default)
confusionMatrix(data = binary_glm, reference = test$Default)
confusionMatrix(data = binary_forest, reference = test$Default)
t
t
predictions_forest <- predict(object = forest, newdata = test[-17], type = "response")
head(predictions_forest, n = 30)
binary_forest <- as.factor(ifelse(predictions_forest > 0.5, 1, 0))
head(binary_forest, n = 30)
binary_forest <- as.factor(binary_forest)
test$Default <- as.factor(test$Default)
set.seed(1234)
confusionMatrix(data = binary_forest, reference = test$Default)
predictions_forest <- predict(object = forest, newdata = test[-17], type = "response")
loan <- Loan_Default_Data_Science_Project
library(readxl)
Loan_Default_Data_Science_Project <- read_excel("Documents/Fall 1/Data Science/Loan Default Data Science Project.xlsx")
View(Loan_Default_Data_Science_Project)
loan <- Loan_Default_Data_Science_Project
library(ggplot2)
library(tidyr)
library(tidyverse)
library(tidyselect)
library(ROCR)
library(rpart)
library(rpart.plot)
library(caret)
library(tree)
library(randomForest)
###LINEAR###
lm1 <- lm(Default ~ . , data = loan)
summary(lm1)
####GLM###. https://rpubs.com/kevinTongam/Logisticregression
train$Default <- as.factor(train$Default)
log.reg <- glm(Default ~ ., data = train, family = "binomial")
summary(log.reg)
#####TUNEDGLM####
log.reg2 <- glm(Default ~ Age + Income + LoanAmount + CreditScore + MonthsEmployed + NumCreditLines + InterestRate + DTIRatio + Education + EmploymentType + MaritalStatus + HasMortgage + HasDependents + LoanPurpose + HasCoSigner, data = train, family = "binomial")
summary(log.reg2)
####GLM###. https://rpubs.com/kevinTongam/Logisticregression
train$Default <- as.factor(train$Default)
#####SPLITTING######
set.seed(123456)
trainIndex <- createDataPartition(loan$Default, p = 0.70, list = FALSE)
train <- loan[trainIndex, ]
test <- loan[-trainIndex, ]
View(train)
View(test)
###LINEAR###
lm1 <- lm(Default ~ . , data = loan)
summary(lm1)
####GLM###. https://rpubs.com/kevinTongam/Logisticregression
train$Default <- as.factor(train$Default)
log.reg <- glm(Default ~ ., data = train, family = "binomial")
summary(log.reg)
#####TUNEDGLM####
log.reg2 <- glm(Default ~ Age + Income + LoanAmount + CreditScore + MonthsEmployed + NumCreditLines + InterestRate + DTIRatio + Education + EmploymentType + MaritalStatus + HasMortgage + HasDependents + LoanPurpose + HasCoSigner, data = train, family = "binomial")
summary(log.reg2)
####ODDSFORINCOME####
odds_function_income <- function(x){
exp(-8.855e-06 * (x))
}
incomes <- c(15000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000, 110000, 120000, 130000, 140000, 150000, 160000)
incomes <- as.data.frame(incomes)
odds_income <- incomes %>%
mutate(odds = (odds_function_income(incomes)))
odds_income
income_plot <- ggplot(odds_income, aes(x = incomes, y = odds)) + geom_line()
income_plot
####ODDSFORLOANAMOUNT####
odds_function_loan <- function(y){
exp(-4.267e-06 * (y))
}
loans <- c(5000, 15000, 30000, 45000, 60000, 75000, 90000, 105000, 120000, 135000, 150000, 165000, 180000, 195000, 210000, 225000, 240000, 255000)
loans <- as.data.frame(loans)
odds_loan <- loans %>%
mutate(odds2 = (odds_function_loan(loans)))
odds_loan
loan_plot <- ggplot(odds_loan, aes(x = loans, y = odds2)) + geom_line()
loan_plot
####ODDSFORCREDITSCORE#####
odds_function_cs <- function(z){
exp(-7.893e-04 * (z))
}
scores <- c(300, 330, 360, 390, 420, 450, 480, 510, 540, 570, 600, 630, 660, 690, 720, 750, 780, 810, 840, 870)
scores <- as.data.frame(scores)
odds_scores <- scores %>%
mutate(odds3 = (odds_function_cs(scores)))
odds_scores
scores_plot <- ggplot(odds_scores, aes(x = scores, y = odds3)) + geom_line()
scores_plot
###PREDICTION####
predictions_glm <- predict(object = log.reg2, newdata = test[-17], type = "response")
head(predictions_glm, n = 30)
binary_glm <- as.factor(ifelse(predictions_glm > 0.5, 1, 0))
head(binary_glm, n = 30)
###CONFUSIONMATRIX####
binary_glm <- as.factor(binary_glm)
test$Default <- as.factor(test$Default)
set.seed(1234)
confusionMatrix(data = binary_glm, reference = test$Default)
####AUC######
pred_ROCR <- prediction(predictions_glm, test$Default)
auc_ROCR <- performance(pred_ROCR, measure = 'auc')
plot(performance(pred_ROCR, measure = 'tpr', x.measure = 'fpr'), colorize = TRUE,
print.cutoffs.at = seq(0, 1, 0.1), text.adj = c(-0.2, 1.7))
####AREAUNDERCURVE####
paste(signif(auc_ROCR@y.values[[1]]))
####FOREST###
forest <- randomForest(Default ~ ., data = train, nodesize=5, ntree = 500, mtry = 4)
predictions_forest <- predict(object = forest, newdata = test[-17], type = "response")
head(predictions_forest, n = 30)
binary_forest <- as.factor(ifelse(predictions_forest > 0.5, 1, 0))
predictions_forest <- predict(object = forest, newdata = test[-17], type = "vector")
predictions_forest <- predict(object = forest, newdata = test[-17], type = "prob")
head(predictions_forest, n = 30)
binary_forest <- as.factor(ifelse(predictions_forest > 0.5, 1, 0))
head(binary_forest, n = 30)
binary_forest <- as.factor(binary_forest)
test$Default_forest <- as.factor(test$Default)
set.seed(1234)
confusionMatrix(data = binary_forest, reference = test$Default_forest)
length(binary_forest)
length(test$Default_forest)
length(binary_glm)
length(test$Default_glm)
###CONFUSIONMATRIX####
binary_glm <- as.factor(binary_glm)
test$Default_glm <- as.factor(test$Default)
set.seed(1234)
confusionMatrix(data = binary_glm, reference = test$Default_glm)
length(binary_forest)
length(test$Default_forest)
binary_forest <- as.factor(binary_forest)
test$Default_forest <- as.factor(test$Default)
set.seed(1234)
confusionMatrix(data = binary_forest, reference = test$Default_forest)
###CONFUSIONMATRIX####
binary_glm <- as.factor(binary_glm)
test$Default <- as.factor(test$Default)
set.seed(1234)
confusionMatrix(data = binary_glm, reference = test$Default)
predictions_forest <- predict(object = forest, newdata = test[-17], type = "prob")
head(predictions_forest, n = 30)
binary_forest <- as.factor(ifelse(predictions_forest > 0.5, 1, 0))
head(binary_forest, n = 30)
binary_forest <- as.factor(binary_forest)
test$Default <- as.factor(test$Default)
set.seed(1234)
confusionMatrix(data = binary_forest, reference = test$Default)
length(binary_forest)
length(test$Default)
length(binary_glm)
predictions_forest <- predict(object = forest, newdata = test[-17], type = "prob")
default_probabilities <- predictions_forest[,2]
binary_forest <- as.factor(ifelse(default_probabilities > 0.5, 1, 0))
head(predictions_forest, n = 30)
head(binary_forest, n = 30)
binary_forest <- as.factor(binary_forest)
test$Default <- as.factor(test$Default)
set.seed(1234)
confusionMatrix(data = binary_forest, reference = test$Default)
length(binary_forest)
length(test$Default)
confusionMatrix(data = binary_glm, reference = test$Default)
confusionMatrix(data = binary_forest, reference = test$Default)
confusionMatrix(data = binary_glm, reference = test$Default)
####AUC######
pred_ROCR <- prediction(predictions_glm, test$Default_glm)
auc_ROCR <- performance(pred_ROCR, measure = 'auc')
plot(performance(pred_ROCR, measure = 'tpr', x.measure = 'fpr'), colorize = TRUE,
print.cutoffs.at = seq(0, 1, 0.1), text.adj = c(-0.2, 1.7))
install.packages("pROC")
install.packages("pROC")
library(pROC)
roc_obj <- roc(true_labels, predicted_scores)
confusionMatrix(data = binary_glm, reference = test$Default)
roc_obj <- roc(true_labels, prediction_glm)
true_labels <- test$Default
roc_obj <- roc(true_labels, prediction_glm)
roc_obj <- roc(true_labels, predictions_glm)
library(pROC)
true_labels <- test$Default
roc_obj <- roc(true_labels, predictions_glm)
roc_obj <- roc(true_labels, binary_glm)
library(pROC)
true_labels <- test$Default
roc_obj <- roc(true_labels, predictions_glm)
plot(roc_obj, main="ROC Curve", col="blue", lwd=2)
abline(h = 0, v = 1, col = "gray", lty = 2)
auc(roc_obj)
text(0.7, 0.2, paste("AUC:", round(auc(roc_obj), 3)), adj=c(0.5,0.5))
roc_obj <- roc(true_labels, predicted_scores)
roc_obj <- roc(true_labels, predictions_glm)
coords(roc_obj, "best", best.method="youden")
###PREDICTION####
predictions_glm <- predict(object = log.reg2, newdata = test[-17], type = "response")
head(predictions_glm, n = 30)
binary_glm <- as.factor(ifelse(predictions_glm > 0.110888, 1, 0))
head(binary_glm, n = 30)
###CONFUSIONMATRIX####
binary_glm <- as.factor(binary_glm)
test$Default <- as.factor(test$Default)
set.seed(1234)
confusionMatrix(data = binary_glm, reference = test$Default)
####AUC######
pred_ROCR <- prediction(predictions_glm, test$Default_glm)
auc_ROCR <- performance(pred_ROCR, measure = 'auc')
plot(performance(pred_ROCR, measure = 'tpr', x.measure = 'fpr'), colorize = TRUE,
print.cutoffs.at = seq(0, 1, 0.1), text.adj = c(-0.2, 1.7))
####AREAUNDERCURVE####
paste(signif(auc_ROCR@y.values[[1]]))
library(ggplot2)
library(tidyr)
library(tidyverse)
library(tidyselect)
library(ROCR)
library(rpart)
library(rpart.plot)
library(caret)
library(tree)
library(randomForest)
prop.table(table(train$Default))
prop.table(table(test$Default))
####GLM###. https://rpubs.com/kevinTongam/Logisticregression
train$Default <- as.factor(train$Default)
log.reg <- glm(Default ~ ., data = train, family = "binomial")
####GLM###. https://rpubs.com/kevinTongam/Logisticregression
train$Default <- as.factor(train$Default)
log.reg <- glm(Default ~ ., data = train, family = "binomial")
summary(log.reg)
#####TUNEDGLM####
log.reg2 <- glm(Default ~ Age + Income + LoanAmount + CreditScore + MonthsEmployed + NumCreditLines + InterestRate + DTIRatio + Education + EmploymentType + MaritalStatus + HasMortgage + HasDependents + LoanPurpose + HasCoSigner, data = train, family = "binomial")
summary(log.reg2)
####ODDSFORINCOME####
odds_function_income <- function(x){
exp(-8.855e-06 * (x))
}
incomes <- c(15000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000, 110000, 120000, 130000, 140000, 150000, 160000)
incomes <- as.data.frame(incomes)
odds_income <- incomes %>%
mutate(odds = (odds_function_income(incomes)))
odds_income
income_plot <- ggplot(odds_income, aes(x = incomes, y = odds)) + geom_line()
income_plot
incomes <- c(15000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000, 110000, 120000, 130000, 140000, 150000, 160000, 1000000)
incomes <- as.data.frame(incomes)
odds_income <- incomes %>%
mutate(odds = (odds_function_income(incomes)))
odds_income
income_plot <- ggplot(odds_income, aes(x = incomes, y = odds)) + geom_line()
income_plot
incomes <- c(15000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000, 110000, 120000, 130000, 140000, 150000, 160000)
incomes <- as.data.frame(incomes)
odds_income <- incomes %>%
mutate(odds = (odds_function_income(incomes)))
odds_income
income_plot <- ggplot(odds_income, aes(x = incomes, y = odds)) + geom_line()
income_plot
####ODDSFORLOANAMOUNT####
odds_function_loan <- function(y){
exp(-4.267e-06 * (y))
}
loans <- c(5000, 15000, 30000, 45000, 60000, 75000, 90000, 105000, 120000, 135000, 150000, 165000, 180000, 195000, 210000, 225000, 240000, 255000)
loans <- as.data.frame(loans)
odds_loan <- loans %>%
mutate(odds2 = (odds_function_loan(loans)))
odds_loan
loan_plot <- ggplot(odds_loan, aes(x = loans, y = odds2)) + geom_line()
loan_plot
####ODDSFORCREDITSCORE#####
odds_function_cs <- function(z){
exp(-7.893e-04 * (z))
}
scores <- c(300, 330, 360, 390, 420, 450, 480, 510, 540, 570, 600, 630, 660, 690, 720, 750, 780, 810, 840, 870)
scores <- as.data.frame(scores)
odds_scores <- scores %>%
mutate(odds3 = (odds_function_cs(scores)))
odds_scores
scores_plot <- ggplot(odds_scores, aes(x = scores, y = odds3)) + geom_line()
scores_plot
###PREDICTION####
predictions_glm <- predict(object = log.reg2, newdata = test[-17], type = "response")
head(predictions_glm, n = 30)
binary_glm <- as.factor(ifelse(predictions_glm > 0.110888, 1, 0))
head(binary_glm, n = 30)
###CONFUSIONMATRIX####
binary_glm <- as.factor(binary_glm)
test$Default <- as.factor(test$Default)
set.seed(1234)
confusionMatrix(data = binary_glm, reference = test$Default)
###PREDICTION####
predictions_glm <- predict(object = log.reg2, newdata = test[-17], type = "response")
head(predictions_glm, n = 30)
binary_glm <- as.factor(ifelse(predictions_glm > 0.6, 1, 0))
head(binary_glm, n = 30)
###CONFUSIONMATRIX####
binary_glm <- as.factor(binary_glm)
test$Default <- as.factor(test$Default)
set.seed(1234)
confusionMatrix(data = binary_glm, reference = test$Default)
binary_glm <- as.factor(ifelse(predictions_glm > 0.4, 1, 0))
head(binary_glm, n = 30)
###CONFUSIONMATRIX####
binary_glm <- as.factor(binary_glm)
test$Default <- as.factor(test$Default)
set.seed(1234)
confusionMatrix(data = binary_glm, reference = test$Default)
binary_glm <- as.factor(ifelse(predictions_glm > 0.5, 1, 0))
head(binary_glm, n = 30)
###CONFUSIONMATRIX####
binary_glm <- as.factor(binary_glm)
test$Default <- as.factor(test$Default)
set.seed(1234)
confusionMatrix(data = binary_glm, reference = test$Default)
####AUC######
pred_ROCR <- prediction(predictions_glm, test$Default_glm)
auc_ROCR <- performance(pred_ROCR, measure = 'auc')
plot(performance(pred_ROCR, measure = 'tpr', x.measure = 'fpr'), colorize = TRUE,
print.cutoffs.at = seq(0, 1, 0.1), text.adj = c(-0.2, 1.7))
####AREAUNDERCURVE####
paste(signif(auc_ROCR@y.values[[1]]))
prop.table(table(train$Default))
prop.table(table(test$Default))
##Logistic model##
logistic <- glm(Default ~ ., data = train, family = "binomial")
summary(logistic)
##Logistic model##
logistic <- glm(Default ~ ., data = train_data, family = "binomial")
loan <- Loan_Default_Data_Science_Project
##Load packages##
library(ggplot2)
library(tidyr)
library(tidyverse)
library(tidyselect)
library(ROCR)
library(rpart)
library(rpart.plot)
library(caret)
library(tree)
library(randomForest)
library(corrplot)
library(RColorBrewer)
##Load file##
data <- read_excel("Loan Default Data Science Project.xlsx")
setwd("~/Documents/Fall 1/Data Science/dukemqm")
##Load file##
data <- read_excel("Loan Default Data Science Project.xlsx")
library(readxl)
##Load file##
data <- read_excel("Loan Default Data Science Project.xlsx")
##Drop Loan ID##
data_drop <- c("LoanID")
data_clean <- data[, !names(data) %in% data_drop]
##Set factors##
data_clean$HasMortgage <- ifelse(data_clean$HasMortgage == "Yes", 1, 0)
data_clean$HasDependents <- ifelse(data_clean$HasDependents == "Yes", 1, 0)
data_clean$HasCoSigner <- ifelse(data_clean$HasCoSigner == "Yes", 1, 0)
education_mapping <- c("High School"= 1, "Bachelor's" = 2, "Master's" = 3, "PhD" = 4)
data_clean$Education <- as.integer(factor(data_clean$Education, levels = names(education_mapping)))
EmploymentType_mapping <- c("Unemployed" = 0, "Self-employed" = 1,"Part-time" = 2, "Full-time" = 3)
data_clean$EmploymentType <- as.integer(factor(data_clean$EmploymentType, levels = names(EmploymentType_mapping)))
MaritalStatus_Mapping <- c("Single" = 0, "Divorced" = 1, "Married" = 2)
data_clean$MaritalStatus <- as.integer(factor(data_clean$MaritalStatus, levels = names(MaritalStatus_Mapping)))
LoanPurpose_mapping <- c("Other" = 0, "Auto" = 1, "Education" = 2, "Home" = 3, "Business" = 4)
data_clean$LoanPurpose <- as.integer(factor(data_clean$LoanPurpose, levels = names(LoanPurpose_mapping)))
data_clean
View(data_clean)
##OOS Split##
n <- count(data_clean)
(n-n%%3)/4/n
test_data <- data_clean[1:63836,]
train_data <- data_clean[63837:255347,]
##Correlation##
Corr <- cor(data_clean)
Corr
CorrplotColor <- brewer.pal(n = 8, name = "BrBG")
corrplot(Corr, method = "color",col = CorrplotColor, tl.col = "black")
##Linear model##
linear <- lm(Default ~ ., data = train_data)
summary(linear)
linear_pred <- predict(linear, newdata = test_data)
##Logistic model##
logistic <- glm(Default ~ ., data = train_data, family = "binomial")
summary(logistic)
logistic_pred <- predict(object = logistic, newdata = test_data, type = "response")
logistic_pred
binary_glm <- as.factor(ifelse(logistic_pred > 0.5, 1, 0))
head(logistic_pred, n = 30)
###CONFUSIONMATRIX####
binary_glm <- as.factor(logistic_pred)
test_data$Default <- as.factor(test_data$Default)
set.seed(1234)
###CONFUSIONMATRIX####
binary_glm <- as.factor(logistic_pred)
test_data$Default <- as.factor(test_data$Default)
set.seed(1234)
confusionMatrix(data = binary_glm, reference = test_data$Default)
##Logistic model##
logistic <- glm(Default ~ ., data = train_data, family = "binomial")
summary(logistic)
logistic_pred <- predict(object = logistic, newdata = test_data, type = "response")
binary_glm <- as.factor(ifelse(logistic_pred > 0.5, 1, 0))
head(logistic_pred, n = 30)
head(binary_glm, n = 30)
###CONFUSIONMATRIX####
binary_glm <- as.factor(binary_glm)
test_data$Default <- as.factor(test_data$Default)
set.seed(1234)
confusionMatrix(data = binary_glm, reference = test_data$Default)
##Evaluate linear model##
residuals_linear <- residuals(linear)
MAE_linear <- mean(abs(residuals_linear))
MSE_linear <- mean(residuals_linear^2)
RMSE_linear <- sqrt(MSE)
RMSE_linear <- sqrt(MSE_linear)
##Evaluate linear model##
residuals_linear <- residuals(linear)
MAE_linear <- mean(abs(residuals_linear))
MAE_linear
MSE_linear <- mean(residuals_linear^2)
MSE_linear
RMSE_linear <- sqrt(MSE_linear)
RMSE_linear
plot(linear, which = 1)
summary(linear)
##Neural network##
# Separate predictors and target variable
train_x <- as.matrix(train_data[, -which(names(train_data) == "Default")])
train_y <- train_data$Default
test_x <- as.matrix(test_data[, -which(names(test_data) == "Default")])
test_y <- test_data$Default
# Normalize the data (important for neural networks)
mean <- apply(train_x, 2, mean)
std <- apply(train_x, 2, sd)
train_x <- scale(train_x, center = mean, scale = std)
test_x <- scale(test_x, center = mean, scale = std)
View(train_x)
install.packages("keras")
library(keras)
nn <- keras_model_sequential()
# Compile the model
nn %>% compile(
optimizer = 'adam',
loss = 'binary_crossentropy',
metrics = c('accuracy')
)
nn <- keras_model_sequential()
Yes
nn <- keras_model_sequential()
reticulate::install_python(version = '<version>')
